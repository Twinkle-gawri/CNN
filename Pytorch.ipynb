{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPjWwU8VffR1Z6GX0UO/qG2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Twinkle-gawri/CNN/blob/main/Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tkNRu9uvYjC"
      },
      "outputs": [],
      "source": [
        "# low level api in pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn #nn library of torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision"
      ],
      "metadata": {
        "id": "hAoRF15MwY-u"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = torchvision.datasets.MNIST('/data',\n",
        "                           train=True,\n",
        "                           download=True,\n",
        "                           transform=torchvision.transforms.ToTensor())\n",
        "test_set = torchvision.datasets.MNIST('/data',\n",
        "                           train=False,\n",
        "                           download=True,\n",
        "                           transform=torchvision.transforms.ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aezKPEM0yUHH",
        "outputId": "4ae7a833-739d-493b-9924-e18ecbabd134"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to /data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 15.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /data/MNIST/raw/train-images-idx3-ubyte.gz to /data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to /data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 485kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /data/MNIST/raw/train-labels-idx1-ubyte.gz to /data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to /data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.40MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /data/MNIST/raw/t10k-images-idx3-ubyte.gz to /data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to /data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.49MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "oZUzMxIgy7tO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9Tqqv0_zTH5",
        "outputId": "347a1619-d6a9-4d38-c0db-617edc0ead9a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(28*28,512) ,  #wx+b , not define number of neurons but we define neurons of this and next layers\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512,256),  # previous layer,next layer\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256,10)\n",
        ")\n",
        "# keras -- defined in list\n",
        "# here linear layer is defined here"
      ],
      "metadata": {
        "id": "D6shKj3kzUmP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2nd way to define\n",
        "layers = [nn.Flatten(),\n",
        "    nn.Linear(28*28,512) ,\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512,256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256,10)]\n",
        "model1 = nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "4Hi4gYxS0hQR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.compile(model).to(device)  # better way to initialize weight and bias , not important over here"
      ],
      "metadata": {
        "id": "U_8BHm871GOA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)  # optim is the lib , important thing -- model.parameter -- optimizer kinko optimize karega"
      ],
      "metadata": {
        "id": "dRIRWJzq1P1j"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_accuracy(output,y_true,N): # no inbuild class, we have to make\n",
        "  # prob of last layers -- output toh hum argmax\n",
        "  y_pred = torch.argmax(output,dim=1)  # output have prob,dtype,shape -- we want only 1st col\n",
        "  correct = (y_pred == y_true).sum().item() #.item to return scaler\n",
        "  return correct/N"
      ],
      "metadata": {
        "id": "y13MXTqb2IC-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_set,batch_size=64,shuffle=True,num_workers=4) # num_worker -- how many will it work parallely\n",
        "test_loader = DataLoader(test_set,batch_size=64,shuffle=False,num_workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4nLtCQc3miE",
        "outputId": "61d5ebc6-8dda-4be7-87a7-f5da09601761"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we have to do custom training over here only\n",
        "def training():\n",
        "  loss = 0\n",
        "  accuracy = 0\n",
        "  model.train() # to initialize the shape of gradient, not imp\n",
        "  for image,label in train_loader: #image size, label\n",
        "    image = image.to(device)\n",
        "    label = label.to(device)\n",
        "    output = model(image)  # model ki last layer ki actn fun not need to define\n",
        "    batch_loss = loss_fn(output,label)\n",
        "    optimizer.zero_grad()\n",
        "    batch_loss.backward()\n",
        "    optimizer.step()  # adjust the parameter accordingly\n",
        "    loss += batch_loss.item()\n",
        "    accuracy += batch_accuracy(output,label,label.shape[0])\n",
        "  print(f'Accuracy is {accuracy/len(train_loader)}') # no. of batches , train_loader.datasets will tell number of examples\n",
        "  print(f'Loss is {loss/len(train_loader)}')"
      ],
      "metadata": {
        "id": "puhwdLaF4Ugb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validation():\n",
        "  loss = 0\n",
        "  accuracy = 0\n",
        "  model.eval()\n",
        "  with torch.no_grad(): # matlab kisi bhi cheez ka gradient nhi compute karna\n",
        "    for image,label in test_loader:\n",
        "      image = image.to(device)\n",
        "      label = label.to(device)\n",
        "      output = model(image)\n",
        "      batch_loss = loss_fn(output,label)\n",
        "      loss += batch_loss.item()\n",
        "      accuracy += batch_accuracy(output,label,label.shape[0])\n",
        "  print(f'Accuracy is {accuracy/len(test_loader)}')\n",
        "  print(f'Loss is {loss/len(test_loader)}')"
      ],
      "metadata": {
        "id": "2g-iaV1p7kFu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "for i in range(epochs):\n",
        "  print(f'Epoch {i+1}')\n",
        "  training()\n",
        "  validation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gn1p2_Z-8mkN",
        "outputId": "c5ff95b8-eb81-4f68-95af-2191aa21cf47"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Accuracy is 0.9324027185501066\n",
            "Loss is 0.2300318783409258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is 0.9665605095541401\n",
            "Loss is 0.10506867192860597\n",
            "Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is 0.972664578891258\n",
            "Loss is 0.08897554981924378\n",
            "Accuracy is 0.9745222929936306\n",
            "Loss is 0.08046432691837578\n",
            "Epoch 3\n",
            "Accuracy is 0.9822594616204691\n",
            "Loss is 0.05636914278532484\n",
            "Accuracy is 0.9770103503184714\n",
            "Loss is 0.06973177712940118\n",
            "Epoch 4\n",
            "Accuracy is 0.9868236940298507\n",
            "Loss is 0.04001654923592172\n",
            "Accuracy is 0.9767117834394905\n",
            "Loss is 0.08207671126733744\n",
            "Epoch 5\n",
            "Accuracy is 0.9894389658848614\n",
            "Loss is 0.03262429725281667\n",
            "Accuracy is 0.9791998407643312\n",
            "Loss is 0.06893535708221844\n",
            "Epoch 6\n",
            "Accuracy is 0.9917044243070362\n",
            "Loss is 0.025610432139771464\n",
            "Accuracy is 0.9811902866242038\n",
            "Loss is 0.07075031232775154\n",
            "Epoch 7\n",
            "Accuracy is 0.9934201759061834\n",
            "Loss is 0.020718702321149113\n",
            "Accuracy is 0.9809912420382165\n",
            "Loss is 0.07313924722567283\n",
            "Epoch 8\n",
            "Accuracy is 0.9938532782515992\n",
            "Loss is 0.018005090183337968\n",
            "Accuracy is 0.9796974522292994\n",
            "Loss is 0.07855511538787865\n",
            "Epoch 9\n",
            "Accuracy is 0.9948027718550106\n",
            "Loss is 0.01566676310802243\n",
            "Accuracy is 0.9837778662420382\n",
            "Loss is 0.07142141083677402\n",
            "Epoch 10\n",
            "Accuracy is 0.9954524253731343\n",
            "Loss is 0.01379195928773325\n",
            "Accuracy is 0.9815883757961783\n",
            "Loss is 0.08053522379133306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_IMmCzGs87PO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}